{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR input: Logistic Regression vs Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('lab_09_train.txt', unpack=True)\n",
    "\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.721668 [[ 0.1005684   0.62609041]]\n",
      "5000 0.693147 [[  3.02305097e-08   5.75125085e-08]]\n",
      "10000 0.693147 [[  3.02305097e-08   5.75125085e-08]]\n",
      "15000 0.693147 [[  3.02305097e-08   5.75125085e-08]]\n",
      "[array([[ 0.5,  0.5,  0.5,  0.5]], dtype=float32), array([[ 1.,  1.,  1.,  1.]], dtype=float32), array([[False,  True,  True, False]], dtype=bool), 0.5]\n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable( tf.random_uniform([1,len(x_data)], -1.0, 1.0) )\n",
    "\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div( 1.0, 1.0 + tf.exp(-h) )\n",
    "cost = -tf.reduce_mean( Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis) )\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in xrange(20000):\n",
    "        sess.run( optimizer, feed_dict={X: x_data, Y: y_data} )\n",
    "        if step % 5000 == 0:\n",
    "            print step, sess.run( cost, feed_dict={X: x_data, Y: y_data} ), sess.run(W)\n",
    "            \n",
    "    # test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis + 0.5), Y)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = tf.reduce_mean( tf.cast(correct_prediction, 'float') )\n",
    "    print sess.run( [hypothesis, tf.floor(hypothesis + 0.5), correct_prediction, accuracy], feed_dict={X: x_data, Y: y_data} )\n",
    "    print \"Accuracy: \", accuracy.eval({X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.709884 [[-0.52016264  0.15535761]\n",
      " [-0.72850347 -0.22847234]] [[ 0.33279434]\n",
      " [ 0.49725112]] Tensor(\"Bias1_3/read:0\", shape=(2,), dtype=float32) Tensor(\"Bias2_3/read:0\", shape=(1,), dtype=float32)\n",
      "5000 0.489938 [[-3.94420052 -0.64380538]\n",
      " [-4.02758503 -1.14481759]] [[-4.31581259]\n",
      " [ 1.75721657]] Tensor(\"Bias1_3/read:0\", shape=(2,), dtype=float32) Tensor(\"Bias2_3/read:0\", shape=(1,), dtype=float32)\n",
      "10000 0.0269741 [[-6.22557592 -4.43546677]\n",
      " [-6.25414276 -4.43960714]] [[-9.49466705]\n",
      " [ 8.88570404]] Tensor(\"Bias1_3/read:0\", shape=(2,), dtype=float32) Tensor(\"Bias2_3/read:0\", shape=(1,), dtype=float32)\n",
      "15000 0.011497 [[-6.63398981 -5.03386545]\n",
      " [-6.65269375 -5.03678417]] [[-10.95162868]\n",
      " [ 10.46949577]] Tensor(\"Bias1_3/read:0\", shape=(2,), dtype=float32) Tensor(\"Bias2_3/read:0\", shape=(1,), dtype=float32)\n",
      "[array([[ 0.00591452],\n",
      "       [ 0.99352914],\n",
      "       [ 0.99351996],\n",
      "       [ 0.0099033 ]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2, 2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [2, 1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "L2 =  tf.sigmoid( tf.matmul(X, W1) + b1 )\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2, W2) + b2 )\n",
    "\n",
    "cost = -tf.reduce_mean( Y * tf.log(hypothesis) + (1 - Y) * tf.log(1.0 - hypothesis) )\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 5000 == 0:\n",
    "            print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W1), sess.run(W2), b1, b2\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print sess.run( [hypothesis, tf.floor(hypothesis + 0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print \"Accuracy:\", accuracy.eval({X: x_data, Y: y_data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using wide neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695587 [[-0.983845   -0.19860178 -0.69784486 -0.17064226  0.19575037 -0.74589014\n",
      "  -0.56897199 -0.07703776 -0.0941787  -0.58280563]\n",
      " [-0.19551569  0.32156786  0.69738013 -0.62232763 -0.23675887 -0.10448418\n",
      "   0.16367304  0.92645949  0.29119799 -0.48097354]] [[ 0.62434852]\n",
      " [ 0.57620496]\n",
      " [-0.79878217]\n",
      " [-0.1515685 ]\n",
      " [-0.15949166]\n",
      " [-0.23786634]\n",
      " [-0.83737874]\n",
      " [ 0.6933707 ]\n",
      " [ 0.59509647]\n",
      " [-0.82000744]] Tensor(\"Bias1_4/read:0\", shape=(10,), dtype=float32) Tensor(\"Bias2_4/read:0\", shape=(1,), dtype=float32)\n",
      "5000 0.0336512 [[-4.76701927 -2.03027964 -4.47518921 -0.36735728  0.18886404 -1.20152617\n",
      "   0.12320431  1.0800072  -1.55973887 -4.66221476]\n",
      " [ 3.04962182  0.31679446  5.77711773 -0.84629589 -0.2766045  -0.21131141\n",
      "   0.6679731   1.37697423 -0.07545896 -4.70585251]] [[ 5.7908988 ]\n",
      " [ 2.38892484]\n",
      " [-7.43508673]\n",
      " [ 1.15601361]\n",
      " [ 0.29552561]\n",
      " [ 1.46285844]\n",
      " [-0.45825627]\n",
      " [ 1.24527311]\n",
      " [ 2.15297675]\n",
      " [-5.96628714]] Tensor(\"Bias1_4/read:0\", shape=(10,), dtype=float32) Tensor(\"Bias2_4/read:0\", shape=(1,), dtype=float32)\n",
      "10000 0.0103848 [[-5.48869801 -2.45187736 -5.11256123 -0.38965455  0.13093546 -1.29518461\n",
      "   0.14181823  1.29877269 -1.73140574 -5.15381384]\n",
      " [ 3.80231023  0.45760345  6.48052263 -1.05839765 -0.37849921 -0.37060711\n",
      "   0.76608378  1.48750961 -0.23512959 -5.11144257]] [[ 7.24575806]\n",
      " [ 2.82524967]\n",
      " [-9.31631851]\n",
      " [ 1.56258154]\n",
      " [ 0.47121772]\n",
      " [ 1.8301729 ]\n",
      " [-0.53279942]\n",
      " [ 1.45657742]\n",
      " [ 2.5492754 ]\n",
      " [-6.82521296]] Tensor(\"Bias1_4/read:0\", shape=(10,), dtype=float32) Tensor(\"Bias2_4/read:0\", shape=(1,), dtype=float32)\n",
      "15000 0.00587692 [[-5.78111744 -2.66372824 -5.37932396 -0.40584755  0.09935442 -1.32587576\n",
      "   0.14817871  1.39313912 -1.7818929  -5.35699701]\n",
      " [ 4.12432814  0.56800312  6.76353264 -1.17262042 -0.4382565  -0.46651483\n",
      "   0.81404239  1.54190016 -0.34122497 -5.28645897]] [[  7.92182827]\n",
      " [  3.03073931]\n",
      " [-10.18281841]\n",
      " [  1.75543272]\n",
      " [  0.55205673]\n",
      " [  2.00226688]\n",
      " [ -0.58432621]\n",
      " [  1.54869473]\n",
      " [  2.73368979]\n",
      " [ -7.22719097]] Tensor(\"Bias1_4/read:0\", shape=(10,), dtype=float32) Tensor(\"Bias2_4/read:0\", shape=(1,), dtype=float32)\n",
      "[array([[ 0.00232101],\n",
      "       [ 0.99628603],\n",
      "       [ 0.99555498],\n",
      "       [ 0.00559165]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "L2 =  tf.sigmoid( tf.matmul(X, W1) + b1 )\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2, W2) + b2 )\n",
    "\n",
    "cost = -tf.reduce_mean( Y * tf.log(hypothesis) + (1 - Y) * tf.log(1.0 - hypothesis) )\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 5000 == 0:\n",
    "            print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W1), sess.run(W2), b1, b2\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print sess.run( [hypothesis, tf.floor(hypothesis + 0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print \"Accuracy:\", accuracy.eval({X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695983 [[-0.2166995   0.45006603 -0.23637293  0.25363451  0.04967713]\n",
      " [ 0.90487099  0.16599664  0.49083501 -0.68595636 -0.6853469 ]] [[ 0.3251698  -0.94339389  0.48530671  0.09753107]\n",
      " [ 0.35090142  0.42844689 -0.82836026  0.19950505]\n",
      " [-0.65185779 -0.06655259 -0.62524444  0.38169926]\n",
      " [-0.16463098  0.26131105  0.58416915 -0.05429392]\n",
      " [ 0.39464092 -0.48898676 -0.98763943 -0.61004072]] [[ 0.32677791]\n",
      " [ 0.39432114]\n",
      " [-0.52228761]\n",
      " [-0.59872323]] Tensor(\"Bias1_5/read:0\", shape=(5,), dtype=float32) Tensor(\"Bias2_5/read:0\", shape=(4,), dtype=float32) Tensor(\"Bias3/read:0\", shape=(1,), dtype=float32)\n",
      "5000 0.6891 [[-0.65491605  0.76230091 -0.25311598  0.29145241  0.16359532]\n",
      " [ 1.30647552  0.69629109  0.54480207 -0.71090603 -0.62630939]] [[ 0.26453128 -1.19685924  0.56283319  0.23140848]\n",
      " [ 0.42178407  0.52909595 -0.9242934   0.09887692]\n",
      " [-0.63298601 -0.13234858 -0.65406108  0.38009432]\n",
      " [-0.17808551  0.29828507  0.66638905 -0.03764731]\n",
      " [ 0.38094816 -0.46569562 -0.91279739 -0.58994132]] [[ 0.34561008]\n",
      " [ 0.81559604]\n",
      " [-0.75006044]\n",
      " [-0.54153162]] Tensor(\"Bias1_5/read:0\", shape=(5,), dtype=float32) Tensor(\"Bias2_5/read:0\", shape=(4,), dtype=float32) Tensor(\"Bias3/read:0\", shape=(1,), dtype=float32)\n",
      "10000 0.0125112 [[-3.98219967  3.54565668 -2.56872487  3.68807936 -0.82775015]\n",
      " [ 5.28281355  4.10021925  0.93843418 -1.98886967 -0.31079653]] [[-0.76823652 -3.85976315  3.69838262  1.29894269]\n",
      " [ 1.22867906  3.14648652 -3.62672806 -0.95072705]\n",
      " [-0.12810653  1.9195981  -2.2270658  -0.18694544]\n",
      " [-1.01512384 -2.05966187  2.90024161  0.72206438]\n",
      " [ 0.48547629  0.47002432 -1.34001756 -0.74925077]] [[ 1.76587939]\n",
      " [ 6.27757072]\n",
      " [-6.7508831 ]\n",
      " [-1.76572728]] Tensor(\"Bias1_5/read:0\", shape=(5,), dtype=float32) Tensor(\"Bias2_5/read:0\", shape=(4,), dtype=float32) Tensor(\"Bias3/read:0\", shape=(1,), dtype=float32)\n",
      "15000 0.00310392 [[-4.26088285  3.83832479 -2.92755127  4.07825994 -0.88720208]\n",
      " [ 5.62072849  4.27250957  1.09772146 -2.26813412 -0.39375255]] [[-1.00083327 -4.252985    4.25407648  1.50170958]\n",
      " [ 1.35929346  3.44067907 -3.9430337  -1.10290408]\n",
      " [-0.01273524  2.26644111 -2.42202973 -0.3105891 ]\n",
      " [-1.15864623 -2.43035436  3.0679419   0.85836381]\n",
      " [ 0.54200149  0.63875514 -1.47850072 -0.80998969]] [[ 2.08274627]\n",
      " [ 7.21787739]\n",
      " [-7.72358084]\n",
      " [-2.09788656]] Tensor(\"Bias1_5/read:0\", shape=(5,), dtype=float32) Tensor(\"Bias2_5/read:0\", shape=(4,), dtype=float32) Tensor(\"Bias3/read:0\", shape=(1,), dtype=float32)\n",
      "20000 0.00169828 [[-4.3646307   3.9479661  -3.06580806  4.22151661 -0.90877217]\n",
      " [ 5.75032091  4.33783245  1.16722977 -2.37637353 -0.43614078]] [[-1.10245895 -4.41941595  4.46653795  1.59284914]\n",
      " [ 1.42040932  3.5546627  -4.0591259  -1.17041349]\n",
      " [ 0.04101662  2.39547467 -2.50163484 -0.36724341]\n",
      " [-1.21882057 -2.56252456  3.13785958  0.91959572]\n",
      " [ 0.57057607  0.70635569 -1.53577507 -0.83842909]] [[ 2.2272687 ]\n",
      " [ 7.61520624]\n",
      " [-8.13100052]\n",
      " [-2.2498498 ]] Tensor(\"Bias1_5/read:0\", shape=(5,), dtype=float32) Tensor(\"Bias2_5/read:0\", shape=(4,), dtype=float32) Tensor(\"Bias3/read:0\", shape=(1,), dtype=float32)\n",
      "[array([[  9.60631587e-04],\n",
      "       [  9.98340130e-01],\n",
      "       [  9.98231590e-01],\n",
      "       [  2.39789858e-03]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")\n",
    "\n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)\n",
    "\n",
    "cost = -tf.reduce_mean( Y * tf.log(hypothesis) + (1 - Y) * tf.log(1.0 - hypothesis) )\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 5000 == 0:\n",
    "            print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W1), sess.run(W2), sess.run(W3), b1, b2, b3\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print sess.run( [hypothesis, tf.floor(hypothesis + 0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "    print \"Accuracy:\", accuracy.eval({X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n"
     ]
    }
   ],
   "source": [
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32, name='X-input')\n",
    "Y = tf.placeholder(tf.float32, name='Y-input')\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2, 2], -1.0, 1.0), name=\"Weight1\")\n",
    "W2 = tf.Variable(tf.random_uniform( [2, 1], -1.0, 1.0), name=\"Weight2\")\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    L2 =  tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    hypothesis =  tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = -tf.reduce_mean( Y * tf.log(hypothesis) + (1 - Y) * tf.log(1.0 - hypothesis) )\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "    \n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    \n",
    "# Add histogram\n",
    "w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "\n",
    "b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "\n",
    "y_hist = tf.summary.histogram(\"y\", Y)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs\", sess.graph)\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(200000):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 20000 == 0:\n",
    "            print step\n",
    "            summary, _ = sess.run([merged, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "            writer.add_summary(summary, step)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
